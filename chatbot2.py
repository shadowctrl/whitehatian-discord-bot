# -*- coding: utf-8 -*-
"""chatbot2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WFLIQmmC6FJf2ZWlaEDiG9O59JT27piH
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import json
import nltk
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.layers import (
    Input,
    Embedding,
    LSTM,
    Dense,
    GlobalMaxPooling1D,
    Flatten,
)
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt

"""IMPORTING THE DATASET"""

import json

with open("content.json") as content:
    data1 = json.load(content)

"""GETTING ALL THE DATA TO LISTS"""

tags = []
inputs = []
responses = {}
for intent in data1["intents"]:
    responses[intent["tag"]] = intent["responses"]
    for lines in intent["input"]:
        inputs.append(lines)
        tags.append(intent["tag"])

"""CONVERTING TO DATAFRAME"""

data = pd.DataFrame({"inputs": inputs, "tags": tags})

data

"""PRE PROCESSING"""

# removing punctuations
import string

data["inputs"] = data["inputs"].apply(
    lambda wrd: [ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation]
)
data["inputs"] = data["inputs"].apply(lambda wrd: "".join(wrd))
data

# tokenize the data
from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer(num_words=2000)
tokenizer.fit_on_texts(data["inputs"])
train = tokenizer.texts_to_sequences(data["inputs"])

# apply padding
from tensorflow.keras.preprocessing.sequence import pad_sequences

x_train = pad_sequences(train)

# encoding the outputs
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
y_train = le.fit_transform(data["tags"])

input_shape = x_train.shape[1]
print(input_shape)

# define vocabulary
vocabulary = len(tokenizer.word_index)
print("Number of unique words: ", vocabulary)
output_length = le.classes_.shape[0]
print("Output Length: ", output_length)

# creating model
i = Input(shape=(input_shape,))
x = Embedding(vocabulary + 1, 10)(i)
x = LSTM(10, return_sequences=True)(x)
x = Flatten()(x)
x = Dense(output_length, activation="softmax")(x)
model = Model(i, x)

# compiling model
model.compile(
    loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"]
)

# training model
train = model.fit(x_train, y_train, epochs=200)

"""MODEL ANALYSIS"""

# plotting model accuracy
plt.plot(train.history["accuracy"], label="Training Set Accuracy")
plt.plot(train.history["loss"], label="Training Set Loss")
plt.legend()

"""TESTING"""

# chatting
import random, requests
from flask import Flask, request

app = Flask(__name__)


@app.route("/request", methods=["POST"])
def hello():
    data = request.get_json()["message"]
    texts_p = []
    # if data.lower().find('movie'):

    texts_p.append(data)

    # Removing punctuation and converting to lowercase
    prediction_input = [
        letters.lower() for letters in data if letters not in string.punctuation
    ]
    prediction_input = "".join(prediction_input)
    texts_p.append(prediction_input)

    # Tokenizing and padding
    prediction_input = tokenizer.texts_to_sequences(texts_p)

    max_len = max(
        len(sublist) for sublist in prediction_input
    )  # Determine the maximum length

    # Pad the inner lists with 0 to make them the same length
    padded_data = [
        sublist + [0] * (max_len - len(sublist)) for sublist in prediction_input
    ]

    # Create a NumPy array from the padded data
    prediction_input = np.array(padded_data)
    prediction_input = np.array(prediction_input).reshape(-1)
    prediction_input = pad_sequences([prediction_input], input_shape)

    # Getting output from model
    output = model.predict(prediction_input)
    output = output.argmax()

    # Finding the right tag and predicting
    response_tag = le.inverse_transform([output])[0]
    response = random.choice(responses[response_tag])
    # if response_tag == 'goodbye':
    #     return response

    return response


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
